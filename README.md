# Understanding-Gradient-descent
I tried understanding gradient descent by building a simple linear model : y = ax + b
Here a is weight and b is bias. 
My actual equation is y = 2x + 1. 
I initialise my model with a = 1, b = 2 and train 300 epochs. 
It finally converges to the actual values when learning rate alpha is 0.1. 
Also you can see that if I fix aplha value as 0.2 the model starts dangling and never converges. 
It helped me understand how gradient descent actually works and how much learning depends on alpha.
